# 🤖 Ollama RAG — Document Question Answering App

This project is a simple **Retrieval-Augmented Generation (RAG)** system built with **LangChain**, **Ollama**, and **FAISS**.  
It allows users to upload a PDF file 📄 and ask natural language questions 💬 — the app retrieves relevant document chunks and generates intelligent answers using a local LLM.

---

## 🚀 Features
✅ Upload any PDF file  
✅ Ask questions about its content  
✅ Uses local **Ollama LLM** (`llama3:instruct`)  
✅ Performs semantic retrieval with **FAISS**  
✅ Clean and simple **Streamlit UI**

---

## 🧩 Tech Stack
| Component | Description |
|------------|--------------|
| 🧠 **Ollama** | Local Large Language Model (LLM) |
| 🧾 **LangChain** | Manages document splitting, retrieval, and chaining |
| 💬 **Streamlit** | Frontend interface |
| 🔍 **FAISS** | Vector similarity search |
| 🧩 **HuggingFace Embeddings** | Text embedding model |
| 📄 **Unstructured** | Document loader for PDF/Text |

---

## ⚙️ Project Structure
